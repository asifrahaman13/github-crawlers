{
    "android_device_xiaomi_cannon": {
        "README.md": {
            "code": "# Redmi Note 9T Device Tree\n\nThe Redmi Note 9T 5G (codenamed _\"cannong\"_) is Mid-end smartphone from Xiaomi. It was announced in January 2021.\n\n## Specsheet\n\n| Device                  | Redmi Note 9T 5G                                                           |\n| ----------------------- | :------------------------------------------------------------------------- |\n| SoC                     | MediaTek Dimensity 800U 5G (7 nm)                                          |\n| CPU                     | Octa-core (2x2.4 GHz Cortex-A76 & 6x2.0 GHz Cortex-A55)                    |\n| GPU                     | Mali-G57 MC3                                                               |\n| Memory                  | 4 GB RAM                                                                   |\n| Shipped Android version | Android 10                                                                 |\n| Storage                 | 64/128 GB                                                                  |\n| Battery                 | Li-Po 5000 mAh, Non-removable                                              |\n| Dimensions              | 161.2 x 77.3 x 9.1 mm (6.35 x 3.04 x 0.36 in)                              |\n| Display                 | 1080 x 2340 pixels, 19.5:9 ratio (~395 ppi density)                        |\n| Rear camera 1           | 48 MP, f/1.8, 26mm (wide), 1/2.0\", 0.8\u00b5m, PDAF                             |\n| Rear camera 2           | 2 MP, f/2.4, (macro)                                                       |\n| Rear camera 3           | 2 MP, f/2.4, (depth)                                                       |\n| Front camera            | 13 MP, f/2.3, 29mm (standard), 1/3.1\", 1.12\u00b5m                              |\n\n## Device picture\n\n![Redmi Note 9T 5G](https://fdn2.gsmarena.com/vv/pics/xiaomi/xiaomi-redmi-note-9t-5g-1.jpg)"
        }
    },
    "android_frameworks_opt_telephony": {
        "README.txt": {
            "code": "This package contains classes used to manage a DataConnection.\n\nA criticial aspect of this class is that most objects in this\npackage run on the same thread except DataConnectionTracker\nThis makes processing efficient as it minimizes context\nswitching and it eliminates issues with multi-threading.\n\nThis can be done because all actions are either asynchronous\nor are known to be non-blocking and fast. At this time only\nDcTesterDeactivateAll takes specific advantage of this\nsingle threading knowledge by using Dcc#mDcListAll so be\nvery careful when making changes that break this assumption.\n\nA related change was in DataConnectionAc I added code that\nchecks to see if the caller is on a different thread. If\nit is then the AsyncChannel#sendMessageSynchronously is\nused. If the caller is on the same thread then a getter\nis used. This allows the DCAC to be used from any thread\nand was required to fix a bug when Dcc called\nPhoneBase#notifyDataConnection which calls DCT#getLinkProperties\nand DCT#getLinkCapabilities which call Dcc all on the same\nthread. Without this change there was a dead lock when\nsendMessageSynchronously blocks.\n\n\n== Testing ==\n\nThe following are Intents that can be sent for testing pruproses on\nDEBUGGABLE builds (userdebug, eng)\n\n*) Causes bringUp and retry requests to fail for all DC's\n\n  adb shell am broadcast -a com.android.internal.telephony.dataconnection.action_fail_bringup --ei counter 2 --ei fail_cause -3\n\n*) Causes all DC's to get torn down, simulating a temporary network outage:\n\n  adb shell am broadcast -a com.android.internal.telephony.dataconnection.action_deactivate_all\n\n*) To simplify testing we also have detach and attach simulations below where {x} is gsm, cdma or sip\n\n  adb shell am broadcast -a com.android.internal.telephony.{x}.action_detached\n  adb shell am broadcast -a com.android.internal.telephony.{x}.action_attached\n\n\n== System properties for Testing ==\n\nOn debuggable builds (userdebug, eng) you can change additional\nsettings through system properties.  These properties can be set with\n\"setprop\" for the current boot, or added to local.prop to persist\nacross boots.\n\ndevice# setprop key value\n\ndevice# echo \"key=value\" >> /data/local.prop\ndevice# chmod 644 /data/local.prop\n\n\n-- Retry configuration --\n\nYou can replace the connection retry configuration.  For example, you\ncould change it to perform 4 retries at 5 second intervals:\n\ndevice# setprop test.data_retry_config \"5000,5000,5000\"\n\n\n-- Roaming --\n\nYou can force the telephony stack to always assume that it's roaming\nto verify higher-level framework functionality:\n\ndevice# setprop telephony.test.forceRoaming true\n"
        }
    },
    "android_prebuilts_clang_host_linux-x86_clang-r437112": {
        "AndroidVersion.txt": {
            "code": "14.0.0\nbased on r437112\nfor additional information on LLVM revision and cherry-picks, see clang_source_info.md"
        }
    },
    "android_vendor_aospa": {
        "merge-caf.py": {
            "code": "#!/usr/bin/env python3\n#\n#\n# Copyright (C) 2021 Paranoid Android\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"\nMerge script for AOSPA\n\n The source directory; this is automatically two folder up because the script\n is located in vendor/aospa/build/tools. Other ROMs will need to change this. The logic is\n as follows:\n\n 1. Get the absolute path of the script with os.path.realpath in case there is a symlink\n    This script may be symlinked by a manifest so we need to account for that\n 2. Get the folder containing the script with dirname\n 3. Move into the folder that is three folders above that one and print it\n\n\"\"\"\n\nimport argparse\nimport os\nimport shutil\nimport subprocess\nimport xml.etree.ElementTree as Et\n\nimport git\nfrom git.exc import GitCommandError\n\nBASE_URL = \"https://source.codeaurora.org/quic/la/\"\nWORKING_DIR = \"{0}/../../../..\".format(os.path.dirname(os.path.realpath(__file__)))\nMANIFEST_NAME = \"aospa.xml\"\nREPOS_TO_MERGE = {}\nREPOS_RESULTS = {}\n\n\n# useful helpers\ndef nice_error():\n    \"\"\" Errors out in a non-ugly way. \"\"\"\n    print(\"Invalid repo, are you sure this repo is on the tag you're merging?\")\n\n\ndef get_manual_repos(args, is_system):\n    \"\"\" Get all manually (optional) specified repos from arguments \"\"\"\n    ret_lst = {}\n    default_repos = list_default_repos(is_system)\n    if args.repos_to_merge:\n        for repo in args.repos_to_merge:\n            if repo not in default_repos:\n                nice_error()\n                return None, None\n            ret_lst[repo] = default_repos[repo]\n    return ret_lst, default_repos\n\n\ndef list_default_repos(is_system):\n    \"\"\" Gathers all repos from split system.xml and vendor.xml \"\"\"\n    default_repos = {}\n    if is_system:\n        with open(\n            \"{0}/.repo/manifests/system.xml\".format(WORKING_DIR)\n        ) as system_manifest:\n            system_root = Et.parse(system_manifest).getroot()\n            for child in system_root:\n                path = child.get(\"path\")\n                if path:\n                    default_repos[path] = child.get(\"name\")\n    else:\n        with open(\n            \"{0}/.repo/manifests/vendor.xml\".format(WORKING_DIR)\n        ) as vendor_manifest:\n            vendor_root = Et.parse(vendor_manifest).getroot()\n            for child in vendor_root:\n                path = child.get(\"path\")\n                if path:\n                    default_repos[path] = child.get(\"name\")\n    return default_repos\n\n\ndef read_custom_manifest(default_repos):\n    \"\"\" Finds all repos that need to be merged \"\"\"\n    print(\"Finding repos to merge...\")\n    with open(\"{0}/.repo/manifests/{1}\".format(WORKING_DIR, MANIFEST_NAME)) as manifest:\n        root = Et.parse(manifest).getroot()\n        removed_repos = []\n        project_repos = []\n        reversed_default = {value: key for key, value in default_repos.items()}\n        for repo in root:\n            if repo.tag == \"remove-project\":\n                removed_repos.append(repo.get(\"name\"))\n            else:\n                if repo.get(\"remote\") == \"aospa\":\n                    project_repos.append(repo.get(\"path\"))\n\n        for repo in removed_repos:\n            if repo in reversed_default:\n                if reversed_default[repo] in project_repos:\n                    REPOS_TO_MERGE[reversed_default[repo]] = repo\n\n\ndef force_sync(repo_lst):\n    \"\"\" Force syncs all the repos that need to be merged \"\"\"\n    print(\"Syncing repos\")\n    for repo in repo_lst:\n        if os.path.isdir(\"{}{}\".format(WORKING_DIR, repo)):\n            shutil.rmtree(\"{}{}\".format(WORKING_DIR, repo))\n\n    cpu_count = str(os.cpu_count())\n    args = [\n        \"repo\",\n        \"sync\",\n        \"-c\",\n        \"--force-sync\",\n        \"-f\",\n        \"--no-clone-bundle\",\n        \"--no-tag\",\n        \"-j\",\n        cpu_count,\n        \"-q\",\n    ] + list(repo_lst.values())\n    subprocess.run(\n        args,\n        check=False,\n    )\n\n\ndef merge(repo_lst, branch):\n    \"\"\" Merges the necessary repos and lists if a repo succeeds or fails \"\"\"\n    failures = []\n    successes = []\n    for repo in repo_lst:\n        print(\"Merging \" + repo)\n        os.chdir(\"{0}/{1}\".format(WORKING_DIR, repo))\n        try:\n            git.cmd.Git().pull(\"{}{}\".format(BASE_URL, repo_lst[repo]), branch)\n            if check_actual_merged_repo(repo, branch):\n                successes.append(repo)\n        except GitCommandError as git_error:\n            print(git_error)\n            failures.append(repo)\n\n    REPOS_RESULTS.update({\"Successes\": successes, \"Failures\": failures})\n\n\ndef merge_manifest(is_system, branch):\n    \"\"\" Updates CAF revision in .repo/manifests \"\"\"\n    with open(\"{0}/.repo/manifests/default.xml\".format(WORKING_DIR)) as manifestxml:\n        tree = Et.parse(manifestxml)\n        root = tree.getroot()\n        if is_system:\n            root.findall(\"default\")[0].set(\"revision\", branch)\n        else:\n            lst = root.findall(\"remote\")\n            remote = None\n            for elem in lst:\n                if elem.attrib[\"name\"] == \"caf_vendor\":\n                    remote = elem\n                    break\n            remote.set(\"revision\", branch)\n        tree.write(\"{0}/.repo/manifests/default.xml\".format(WORKING_DIR))\n        cpu_count = str(os.cpu_count())\n        subprocess.run(\n            [\n                \"repo\",\n                \"sync\",\n                \"-c\",\n                \"--force-sync\",\n                \"-f\",\n                \"--no-clone-bundle\",\n                \"--no-tag\",\n                \"-j\",\n                cpu_count,\n                \"-q\",\n                \"-d\",\n            ],\n            check=False,\n        )\n        git_repo = git.Repo(\"{0}/.repo/manifests\".format(WORKING_DIR))\n        git_repo.git.execute([\"git\", \"checkout\", \".\"])\n\n\ndef check_actual_merged_repo(repo, branch):\n    \"\"\"Gets all the repos that were actually merged and\n    not the ones that were just up-to-date\"\"\"\n    git_repo = git.Repo(\"{0}/{1}\".format(WORKING_DIR, repo))\n    commits = list(git_repo.iter_commits(\"HEAD\", max_count=1))\n    result = commits[0].message\n    if branch.split(\"/\")[2] in result:\n        return True\n    return False\n\n\ndef print_results(branch):\n    \"\"\" Prints all all repos that will need to be manually fixed \"\"\"\n    if REPOS_RESULTS[\"Failures\"]:\n        print(\"\\nThese repos failed to merge, fix manually: \")\n        for failure in REPOS_RESULTS[\"Failures\"]:\n            print(failure)\n    if REPOS_RESULTS[\"Successes\"]:\n        print(\"\\nRepos that merged successfully: \")\n        for success in REPOS_RESULTS[\"Successes\"]:\n            print(success)\n    print()\n    if not REPOS_RESULTS[\"Failures\"] and REPOS_RESULTS[\"Successes\"]:\n        print(\n            \"{0} merged successfully! Compile and test before pushing to GitHub.\".format(\n                branch.split(\"/\")[2]\n            )\n        )\n    elif not REPOS_RESULTS[\"Failures\"] and not REPOS_RESULTS[\"Successes\"]:\n        print(\"Unable to retrieve any results\")\n\n\ndef main():\n    \"\"\"Gathers and merges all repos from CAF and\n    reports all repos that need to be fixed manually\"\"\"\n\n    parser = argparse.ArgumentParser(description=\"Merge a CAF revision.\")\n    parser.add_argument(\n        \"branch_to_merge\",\n        metavar=\"branch\",\n        type=str,\n        help=\"a tag to merge from source.codeaurora.org\",\n    )\n    parser.add_argument(\n        \"--repos\",\n        dest=\"repos_to_merge\",\n        nargs=\"*\",\n        type=str,\n        help=\"path of repos to merge\",\n    )\n    parser.add_argument(\n        \"--merge-manifest\",\n        dest=\"merge_manifest\",\n        action=\"store_true\",\n        help=\"automatically update manifest before merging repos\",\n    )\n    parser.add_argument(\n        \"--dry-run\",\n        dest=\"dry_run\",\n        action=\"store_true\",\n        help=\"Dry run the merge script (for testing purposes)\",\n    )\n    args = parser.parse_args()\n\n    branch = \"refs/tags/{}\".format(args.branch_to_merge)\n\n    is_system = \"QSSI\" in branch\n    repo_lst, default_repos = get_manual_repos(args, is_system)\n    if repo_lst is None and default_repos is None:\n        return\n    if len(repo_lst) == 0:\n        read_custom_manifest(default_repos)\n        if args.dry_run:\n            print(list(REPOS_TO_MERGE.keys()))\n            quit()\n        if REPOS_TO_MERGE:\n            if args.merge_manifest:\n                merge_manifest(is_system, branch)\n            force_sync(REPOS_TO_MERGE)\n            merge(REPOS_TO_MERGE, branch)\n            os.chdir(WORKING_DIR)\n            print_results(branch)\n        else:\n            print(\"No repos to sync\")\n    else:\n        force_sync(repo_lst)\n        merge(repo_lst, branch)\n        os.chdir(WORKING_DIR)\n        print_results(branch)\n\n\nif __name__ == \"__main__\":\n    # execute only if run as a script\n    main()\n"
        },
        "repopick.py": {
            "code": "#!/usr/bin/env python\n#\n# Copyright (C) 2013-15 The CyanogenMod Project\n#           (C) 2017    The LineageOS Project\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n\n#\n# Run repopick.py -h for a description of this utility.\n#\n\nfrom __future__ import print_function\n\nimport sys\nimport json\nimport os\nimport subprocess\nimport re\nimport argparse\nimport textwrap\nfrom functools import cmp_to_key\nfrom xml.etree import ElementTree\n\ntry:\n    import requests\nexcept ImportError:\n    try:\n        # For python3\n        import urllib.error\n        import urllib.request\n    except ImportError:\n        # For python2\n        import imp\n        import urllib2\n        urllib = imp.new_module('urllib')\n        urllib.error = urllib2\n        urllib.request = urllib2\n\n\n# cmp() is not available in Python 3, define it manually\n# See https://docs.python.org/3.0/whatsnew/3.0.html#ordering-comparisons\ndef cmp(a, b):\n    return (a > b) - (a < b)\n\n\n# Verifies whether pathA is a subdirectory (or the same) as pathB\ndef is_subdir(a, b):\n    a = os.path.realpath(a) + '/'\n    b = os.path.realpath(b) + '/'\n    return b == a[:len(b)]\n\n\ndef fetch_query_via_ssh(remote_url, query):\n    \"\"\"Given a remote_url and a query, return the list of changes that fit it\n       This function is slightly messy - the ssh api does not return data in the same structure as the HTTP REST API\n       We have to get the data, then transform it to match what we're expecting from the HTTP RESET API\"\"\"\n    if remote_url.count(':') == 2:\n        (uri, userhost, port) = remote_url.split(':')\n        userhost = userhost[2:]\n    elif remote_url.count(':') == 1:\n        (uri, userhost) = remote_url.split(':')\n        userhost = userhost[2:]\n        port = 29418\n    else:\n        raise Exception('Malformed URI: Expecting ssh://[user@]host[:port]')\n\n\n    out = subprocess.check_output(['ssh', '-x', '-p{0}'.format(port), userhost, 'gerrit', 'query', '--format=JSON --patch-sets --current-patch-set', query])\n    if not hasattr(out, 'encode'):\n        out = out.decode()\n    reviews = []\n    for line in out.split('\\n'):\n        try:\n            data = json.loads(line)\n            # make our data look like the http rest api data\n            review = {\n                'branch': data['branch'],\n                'change_id': data['id'],\n                'current_revision': data['currentPatchSet']['revision'],\n                'number': int(data['number']),\n                'revisions': {patch_set['revision']: {\n                    '_number': int(patch_set['number']),\n                    'fetch': {\n                        'ssh': {\n                            'ref': patch_set['ref'],\n                            'url': 'ssh://{0}:{1}/{2}'.format(userhost, port, data['project'])\n                        }\n                    },\n                    'commit': {\n                        'parents': [{ 'commit': parent } for parent in patch_set['parents']]\n                    },\n                } for patch_set in data['patchSets']},\n                'subject': data['subject'],\n                'project': data['project'],\n                'status': data['status']\n            }\n            reviews.append(review)\n        except:\n            pass\n    args.quiet or print('Found {0} reviews'.format(len(reviews)))\n    return reviews\n\n\ndef fetch_query_via_http(remote_url, query):\n    if \"requests\" in sys.modules:\n        auth = None\n        if os.path.isfile(os.getenv(\"HOME\") + \"/.gerritrc\"):\n            f = open(os.getenv(\"HOME\") + \"/.gerritrc\", \"r\")\n            for line in f:\n                parts = line.rstrip().split(\"|\")\n                if parts[0] in remote_url:\n                    auth = requests.auth.HTTPBasicAuth(username=parts[1], password=parts[2])\n        statusCode = '-1'\n        if auth:\n            url = '{0}/a/changes/?q={1}&o=CURRENT_REVISION&o=ALL_REVISIONS&o=ALL_COMMITS'.format(remote_url, query)\n            data = requests.get(url, auth=auth)\n            statusCode = str(data.status_code)\n        if statusCode != '200':\n            #They didn't get good authorization or data, Let's try the old way\n            url = '{0}/changes/?q={1}&o=CURRENT_REVISION&o=ALL_REVISIONS&o=ALL_COMMITS'.format(remote_url, query)\n            data = requests.get(url)\n        reviews = json.loads(data.text[5:])\n    else:\n        \"\"\"Given a query, fetch the change numbers via http\"\"\"\n        url = '{0}/changes/?q={1}&o=CURRENT_REVISION&o=ALL_REVISIONS&o=ALL_COMMITS'.format(remote_url, query)\n        data = urllib.request.urlopen(url).read().decode('utf-8')\n        reviews = json.loads(data[5:])\n\n    for review in reviews:\n        review['number'] = review.pop('_number')\n\n    return reviews\n\n\ndef fetch_query(remote_url, query):\n    \"\"\"Wrapper for fetch_query_via_proto functions\"\"\"\n    if remote_url[0:3] == 'ssh':\n        return fetch_query_via_ssh(remote_url, query)\n    elif remote_url[0:4] == 'http':\n        return fetch_query_via_http(remote_url, query.replace(' ', '+'))\n    else:\n        raise Exception('Gerrit URL should be in the form http[s]://hostname/ or ssh://[user@]host[:port]')\n\nif __name__ == '__main__':\n    # Default to Paranoid Android Gerrit\n    default_gerrit = 'https://gerrit.aospa.co'\n\n    parser = argparse.ArgumentParser(formatter_class=argparse.RawDescriptionHelpFormatter, description=textwrap.dedent('''\\\n        repopick.py is a utility to simplify the process of cherry picking\n        patches from Paranoid Android's Gerrit instance (or any gerrit instance of your choosing)\n\n        Given a list of change numbers, repopick will cd into the project path\n        and cherry pick the latest patch available.\n\n        With the --start-branch argument, the user can specify that a branch\n        should be created before cherry picking. This is useful for\n        cherry-picking many patches into a common branch which can be easily\n        abandoned later (good for testing other's changes.)\n\n        The --abandon-first argument, when used in conjunction with the\n        --start-branch option, will cause repopick to abandon the specified\n        branch in all repos first before performing any cherry picks.'''))\n    parser.add_argument('change_number', nargs='*', help='change number to cherry pick.  Use {change number}/{patchset number} to get a specific revision.')\n    parser.add_argument('-i', '--ignore-missing', action='store_true', help='do not error out if a patch applies to a missing directory')\n    parser.add_argument('-ch', '--checkout', action='store_true', help='checkout instead of cherry pick')\n    parser.add_argument('-s', '--start-branch', nargs=1, help='start the specified branch before cherry picking')\n    parser.add_argument('-r', '--reset', action='store_true', help='reset to initial state (abort cherry-pick) if there is a conflict')\n    parser.add_argument('-a', '--abandon-first', action='store_true', help='before cherry picking, abandon the branch specified in --start-branch')\n    parser.add_argument('-b', '--auto-branch', action='store_true', help='shortcut to \"--start-branch auto --abandon-first --ignore-missing\"')\n    parser.add_argument('-q', '--quiet', action='store_true', help='print as little as possible')\n    parser.add_argument('-v', '--verbose', action='store_true', help='print extra information to aid in debug')\n    parser.add_argument('-f', '--force', action='store_true', help='force cherry pick even if change is closed')\n    parser.add_argument('-p', '--pull', action='store_true', help='execute pull instead of cherry-pick')\n    parser.add_argument('-P', '--path', help='use the specified path for the change')\n    parser.add_argument('-t', '--topic', nargs='*', help='pick all commits from the specified topics')\n    parser.add_argument('-Q', '--query', help='pick all commits using the specified query')\n    parser.add_argument('-g', '--gerrit', default=default_gerrit, help='Gerrit Instance to use. Form proto://[user@]host[:port]')\n    parser.add_argument('-e', '--exclude', nargs=1, help='exclude a list of commit numbers separated by a ,')\n    parser.add_argument('-c', '--check-picked', type=int, default=10, help='pass the amount of commits to check for already picked changes')\n    args = parser.parse_args()\n    if not args.start_branch and args.abandon_first:\n        parser.error('if --abandon-first is set, you must also give the branch name with --start-branch')\n    if args.auto_branch:\n        args.abandon_first = True\n        args.ignore_missing = True\n        if not args.start_branch:\n            args.start_branch = ['auto']\n    if args.quiet and args.verbose:\n        parser.error('--quiet and --verbose cannot be specified together')\n\n    if (1 << bool(args.change_number) << bool(args.topic) << bool(args.query)) != 2:\n        parser.error('One (and only one) of change_number, topic, and query are allowed')\n\n    # Change current directory to the top of the tree\n    if 'ANDROID_BUILD_TOP' in os.environ:\n        top = os.environ['ANDROID_BUILD_TOP']\n\n        if not is_subdir(os.getcwd(), top):\n            sys.stderr.write('ERROR: You must run this tool from within $ANDROID_BUILD_TOP!\\n')\n            sys.exit(1)\n        os.chdir(os.environ['ANDROID_BUILD_TOP'])\n\n    # Sanity check that we are being run from the top level of the tree\n    if not os.path.isdir('.repo'):\n        sys.stderr.write('ERROR: No .repo directory found. Please run this from the top of your tree.\\n')\n        sys.exit(1)\n\n    # If --abandon-first is given, abandon the branch before starting\n    if args.abandon_first:\n        # Determine if the branch already exists; skip the abandon if it does not\n        plist = subprocess.check_output(['repo', 'info'])\n        if not hasattr(plist, 'encode'):\n            plist = plist.decode()\n        needs_abandon = False\n        for pline in plist.splitlines():\n            matchObj = re.match(r'Local Branches.*\\[(.*)\\]', pline)\n            if matchObj:\n                local_branches = re.split('\\s*,\\s*', matchObj.group(1))\n                if any(args.start_branch[0] in s for s in local_branches):\n                    needs_abandon = True\n\n        if needs_abandon:\n            # Perform the abandon only if the branch already exists\n            if not args.quiet:\n                print('Abandoning branch: %s' % args.start_branch[0])\n            subprocess.check_output(['repo', 'abandon', args.start_branch[0]])\n            if not args.quiet:\n                print('')\n\n    # Get the master manifest from repo\n    #   - convert project name and revision to a path\n    project_name_to_data = {}\n    manifest = subprocess.check_output(['repo', 'manifest'])\n    xml_root = ElementTree.fromstring(manifest)\n    projects = xml_root.findall('project')\n    remotes = xml_root.findall('remote')\n    default_revision = xml_root.findall('default')[0].get('revision')\n\n    #dump project data into the a list of dicts with the following data:\n    #{project: {path, revision}}\n\n    for project in projects:\n        name = project.get('name')\n        path = project.get('path')\n        revision = project.get('revision')\n        if revision is None:\n            for remote in remotes:\n                if remote.get('name') == project.get('remote'):\n                    revision = remote.get('revision')\n            if revision is None:\n                revision = default_revision\n\n        if not name in project_name_to_data:\n            project_name_to_data[name] = {}\n        revision = revision.split('refs/heads/')[-1]\n        project_name_to_data[name][revision] = path\n\n    # get data on requested changes\n    reviews = []\n    change_numbers = []\n\n    def cmp_reviews(review_a, review_b):\n        current_a = review_a['current_revision']\n        parents_a = [r['commit'] for r in review_a['revisions'][current_a]['commit']['parents']]\n        current_b = review_b['current_revision']\n        parents_b = [r['commit'] for r in review_b['revisions'][current_b]['commit']['parents']]\n        if current_a in parents_b:\n            return -1\n        elif current_b in parents_a:\n            return 1\n        else:\n            return cmp(review_a['number'], review_b['number'])\n\n    if not args.force:\n        if args.gerrit[0:3] == 'ssh':\n            query=\"status:open topic:{}\"\n        else:\n            query=\"status:open+topic:{}\"\n    else:\n        query=\"topic:{}\"\n    if args.topic:\n        for t in args.topic:\n            # Store current topic to process for change_numbers\n            topic = fetch_query(args.gerrit, query.format(t))\n            # Append topic to reviews, for later reference\n            reviews += topic\n            # Cycle through the current topic to get the change numbers\n            change_numbers += sorted([str(r['number']) for r in topic], key=int)\n    if args.query:\n        reviews = fetch_query(args.gerrit, args.query)\n        change_numbers = [str(r['number']) for r in sorted(reviews, key=cmp_to_key(cmp_reviews))]\n    if args.change_number:\n        change_url_re = re.compile('https?://.+?/([0-9]+(?:/[0-9]+)?)/?')\n        for c in args.change_number:\n            change_number = change_url_re.findall(c)\n            if change_number:\n                change_numbers.extend(change_number)\n            elif '-' in c:\n                templist = c.split('-')\n                for i in range(int(templist[0]), int(templist[1]) + 1):\n                    change_numbers.append(str(i))\n            else:\n                change_numbers.append(c)\n        reviews = fetch_query(args.gerrit, ' OR '.join('change:{0}'.format(x.split('/')[0]) for x in change_numbers))\n\n    # make list of things to actually merge\n    mergables = []\n\n    # If --exclude is given, create the list of commits to ignore\n    exclude = []\n    if args.exclude:\n        exclude = args.exclude[0].split(',')\n\n    for change in change_numbers:\n        patchset = None\n        if '/' in change:\n            (change, patchset) = change.split('/')\n\n        if change in exclude:\n            continue\n\n        change = int(change)\n\n        if patchset:\n            patchset = int(patchset)\n\n        review = next((x for x in reviews if x['number'] == change), None)\n        if review is None:\n            print('Change %d not found, skipping' % change)\n            continue\n\n        mergables.append({\n            'subject': review['subject'],\n            'project': review['project'],\n            'branch': review['branch'],\n            'change_id': review['change_id'],\n            'change_number': review['number'],\n            'status': review['status'],\n            'fetch': None,\n            'patchset': review['revisions'][review['current_revision']]['_number'],\n        })\n\n        mergables[-1]['fetch'] = review['revisions'][review['current_revision']]['fetch']\n        mergables[-1]['id'] = change\n        if patchset:\n            try:\n                mergables[-1]['fetch'] = [review['revisions'][x]['fetch'] for x in review['revisions'] if review['revisions'][x]['_number'] == patchset][0]\n                mergables[-1]['id'] = '{0}/{1}'.format(change, patchset)\n                mergables[-1]['patchset'] = patchset\n            except (IndexError, ValueError):\n                args.quiet or print('ERROR: The patch set {0}/{1} could not be found, using CURRENT_REVISION instead.'.format(change, patchset))\n\n    for item in mergables:\n        args.quiet or print('Applying change number {0}...'.format(item['id']))\n        # Check if change is open and exit if it's not, unless -f is specified\n        if (item['status'] != 'OPEN' and item['status'] != 'NEW' and item['status'] != 'DRAFT') and not args.query:\n            if args.force:\n                print('!! Force-picking a closed change !!\\n')\n            else:\n                print('Change status is ' + item['status'] + '. Skipping the cherry pick.\\nUse -f to force this pick.')\n                continue\n\n        # Convert the project name to a project path\n        #   - check that the project path exists\n        project_path = None\n\n        if item['project'] in project_name_to_data and item['branch'] in project_name_to_data[item['project']]:\n            project_path = project_name_to_data[item['project']][item['branch']]\n        elif 'https://android-review.googlesource.com' in args.gerrit:\n            project_path = item['project'].replace(\"platform/\", \"\")\n        elif args.path:\n            project_path = args.path\n        elif item['project'] in project_name_to_data and len(project_name_to_data[item['project']]) == 1:\n            local_branch = list(project_name_to_data[item['project']])[0]\n            project_path = project_name_to_data[item['project']][local_branch]\n            print('WARNING: Project {0} has a different branch (\"{1}\" != \"{2}\")'.format(project_path, local_branch, item['branch']))\n        elif args.ignore_missing:\n            print('WARNING: Skipping {0} since there is no project directory for: {1}\\n'.format(item['id'], item['project']))\n            continue\n        else:\n            sys.stderr.write('ERROR: For {0}, could not determine the project path for project {1}\\n'.format(item['id'], item['project']))\n            sys.exit(1)\n\n        # If --start-branch is given, create the branch (more than once per path is okay; repo ignores gracefully)\n        if args.start_branch:\n            subprocess.check_output(['repo', 'start', args.start_branch[0], project_path])\n\n        # Determine the maximum commits to check already picked changes\n        check_picked_count = args.check_picked\n        branch_commits_count = int(subprocess.check_output(['git', 'rev-list', '--count', 'HEAD'], cwd=project_path))\n        if branch_commits_count <= check_picked_count:\n            check_picked_count = branch_commits_count - 1\n\n        # Check if change is already picked to HEAD...HEAD~check_picked_count\n        found_change = False\n        for i in range(0, check_picked_count):\n            if subprocess.call(['git', 'cat-file', '-e', 'HEAD~{0}'.format(i)], cwd=project_path, stderr=open(os.devnull, 'wb')):\n                continue\n            output = subprocess.check_output(['git', 'show', '-q', 'HEAD~{0}'.format(i)], cwd=project_path)\n            # make sure we have a string on Python 3\n            if isinstance(output, bytes):\n                output = output.decode('utf-8')\n            output = output.split()\n            if 'Change-Id:' in output:\n                head_change_id = ''\n                for j,t in enumerate(reversed(output)):\n                    if t == 'Change-Id:':\n                        head_change_id = output[len(output) - j]\n                        break\n                if head_change_id.strip() == item['change_id']:\n                    print('Skipping {0} - already picked in {1} as HEAD~{2}'.format(item['id'], project_path, i))\n                    found_change = True\n                    break\n        if found_change:\n            continue\n\n        # Print out some useful info\n        if not args.quiet:\n            print(u'--> Subject       : \"{0}\"'.format(item['subject']))\n            print('--> Project path  : {0}'.format(project_path))\n            print('--> Change number : {0} (Patch Set {1})'.format(item['id'], item['patchset']))\n\n        if 'anonymous http' in item['fetch']:\n            method = 'anonymous http'\n        elif 'https://android-review.googlesource.com' in args.gerrit:\n            method = 'http'\n        else:\n            method = 'ssh'\n\n        # Try fetching from GitHub first if using default gerrit\n        if args.gerrit == default_gerrit:\n            if args.verbose:\n                print('Trying to fetch the change from GitHub')\n\n            if args.pull:\n                cmd = ['git pull --no-edit aospa', item['fetch'][method]['ref']]\n            else:\n                cmd = ['git fetch aospa', item['fetch'][method]['ref']]\n            if args.quiet:\n                cmd.append('--quiet')\n            else:\n                print('--> Command       : \"{0}\"'.format(' '.join(cmd)))\n            result = subprocess.call([' '.join(cmd)], cwd=project_path, shell=True)\n            FETCH_HEAD = '{0}/.git/FETCH_HEAD'.format(project_path)\n            if result != 0 and os.stat(FETCH_HEAD).st_size != 0:\n                print('ERROR: git command failed')\n                sys.exit(result)\n        # Check if it worked\n        if args.gerrit != default_gerrit or os.stat(FETCH_HEAD).st_size == 0:\n            # If not using the default gerrit or github failed, fetch from gerrit.\n            if args.verbose:\n                if args.gerrit == default_gerrit:\n                    print('Fetching from GitHub didn\\'t work, trying to fetch the change from Gerrit')\n                else:\n                    print('Fetching from {0}'.format(args.gerrit))\n\n            if args.pull:\n                cmd = ['git pull --no-edit', item['fetch'][method]['url'], item['fetch'][method]['ref']]\n            else:\n                cmd = ['git fetch', item['fetch'][method]['url'], item['fetch'][method]['ref']]\n            if args.quiet:\n                cmd.append('--quiet')\n            else:\n                print('--> Command       : \"{0}\"'.format(' '.join(cmd)))\n            result = subprocess.call([' '.join(cmd)], cwd=project_path, shell=True)\n            if result != 0:\n                print('ERROR: git command failed')\n                sys.exit(result)\n        # Perform the cherry-pick or checkout\n        if not args.pull:\n            if args.checkout:\n                cmd = ['git checkout FETCH_HEAD']\n            else:\n                cmd = ['git cherry-pick --ff FETCH_HEAD']\n            if args.quiet:\n                cmd_out = open(os.devnull, 'wb')\n            else:\n                cmd_out = None\n            result = subprocess.call(cmd, cwd=project_path, shell=True, stdout=cmd_out, stderr=cmd_out)\n            if result != 0:\n                cmd = ['git diff-index --quiet HEAD --']\n                result = subprocess.call(cmd, cwd=project_path, shell=True, stdout=cmd_out, stderr=cmd_out)\n                if result == 0:\n                    print('WARNING: git command resulted with an empty commit, aborting cherry-pick')\n                    cmd = ['git cherry-pick --abort']\n                    subprocess.call(cmd, cwd=project_path, shell=True, stdout=cmd_out, stderr=cmd_out)\n                elif args.reset:\n                    print('ERROR: git command failed, aborting cherry-pick')\n                    cmd = ['git cherry-pick --abort']\n                    subprocess.call(cmd, cwd=project_path, shell=True, stdout=cmd_out, stderr=cmd_out)\n                    sys.exit(result)\n                else:\n                    print('ERROR: git command failed')\n                    sys.exit(result)\n        if not args.quiet:\n            print('')\n"
        },
        "roomservice.py": {
            "code": "#!/usr/bin/env python3\n\n# roomservice: Android device repository management utility.\n# Copyright (C) 2013 Cybojenix <anthonydking@gmail.com>\n# Copyright (C) 2013 The OmniROM Project\n# Copyright (C) 2015-2019 ParanoidAndroid Project\n#\n# This program is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with this program.  If not, see <http://www.gnu.org/licenses/>.\n\nimport json\nimport os\nimport sys\nfrom xml.etree import ElementTree as ET\n\nextra_manifests_dir = '.repo/manifests/'\nupstream_manifest_path = '.repo/manifest.xml'\nlocal_manifests_dir = '.repo/local_manifests'\nroomservice_manifest_path = local_manifests_dir + '/roomservice.xml'\ndependencies_json_path = 'vendor/aospa/products/%s/aospa.dependencies'\n\n# Indenting code from https://stackoverflow.com/a/4590052\ndef indent(elem, level=0):\n    i = \"\\n\" + level * \"  \"\n    if len(elem):\n        if not elem.text or not elem.text.strip():\n            elem.text = i + \"  \"\n        if not elem.tail or not elem.tail.strip():\n            elem.tail = i\n        for elem in elem:\n            indent(elem, level + 1)\n        if not elem.tail or not elem.tail.strip():\n            elem.tail = i\n    else:\n        if level and (not elem.tail or not elem.tail.strip()):\n            elem.tail = i\n\ndef recurse_include(manifest):\n    includes = manifest.findall('include')\n    if includes is not None:\n        for file in includes:\n            extra_manifest = ET.parse(extra_manifests_dir + file.get('name')).getroot()\n            for elem in extra_manifest:\n                manifest.append(elem)\n            for elem in recurse_include(extra_manifest):\n                manifest.append(elem)\n    return manifest\n\nif __name__ == '__main__':\n    if not os.path.isdir(local_manifests_dir):\n        os.mkdir(local_manifests_dir)\n\n    if len(sys.argv) <= 1:\n        raise ValueError('The first argument must be the product.')\n    product = sys.argv[1]\n\n    try:\n        device = product[product.index('_') + 1:]\n    except ValueError:\n        device = product\n\n    dependencies_json_path %= device\n    if not os.path.isfile(dependencies_json_path):\n        raise ValueError('No dependencies file could be found for the device (%s).' % device)\n    dependencies = json.loads(open(dependencies_json_path, 'r').read())\n\n    try:\n        upstream_manifest = ET.parse(upstream_manifest_path).getroot()\n    except (IOError, ET.ParseError):\n        upstream_manifest = ET.Element('manifest')\n\n    recurse_include(upstream_manifest)\n\n    try:\n        roomservice_manifest = ET.parse(roomservice_manifest_path).getroot()\n    except (IOError, ET.ParseError):\n        roomservice_manifest = ET.Element('manifest')\n\n    syncable_projects = []\n\n    mentioned_projects = []\n\n    # Clean up all the <remove-project> elements.\n    for removable_project in roomservice_manifest.findall('remove-project'):\n        name = removable_project.get('name')\n\n        path = None\n        for project in upstream_manifest.findall('project'):\n            if project.get('name') == name:\n                path = project.get('path')\n                break\n\n        if path is None:\n            # The upstream manifest doesn't know this project, so drop it.\n            roomservice_manifest.remove(removable_project)\n            continue\n\n        found_in_dependencies = False\n        for dependency in dependencies:\n            if dependency.get('target_path') == path:\n                found_in_dependencies = True\n                break\n\n        if not found_in_dependencies:\n            # We don't need special dependencies for this project, so drop it and sync it up.\n            roomservice_manifest.remove(removable_project)\n            syncable_projects.append(path)\n            for project in roomservice_manifest.findall('project'):\n                if project.get('path') == path:\n                    roomservice_manifest.remove(project)\n                    break\n\n    # Make sure our <project> elements are set.\n    for dependency in dependencies:\n        path = dependency.get('target_path')\n        name = dependency.get('repository')\n        remote = dependency.get('remote')\n        revision = dependency.get('revision')\n        clone_depth = dependency.get('clone-depth')\n\n        # Store path of every repositories mentioned in dependencies.\n        mentioned_projects.append(path)\n\n        # Make sure the required remote exists in the upstream manifest.\n        found_remote = False\n        for known_remote in upstream_manifest.findall('remote'):\n            if known_remote.get('name') == remote:\n                found_remote = True\n                break\n        if not found_remote:\n            raise ValueError('No remote declaration could be found for the %s project. (%s)' % (name, remote))\n\n        modified_project = False\n        found_in_roomservice = False\n\n        # In case the project was already added, update it.\n        for project in roomservice_manifest.findall('project'):\n            if project.get('name') == name or project.get('path') == path:\n                if found_in_roomservice:\n                    roomservice_manifest.remove(project)\n                else:\n                    found_in_roomservice = True\n                    msg = ''\n                    if project.get('path') != path:\n                        modified_project = True\n                        project.set('path', path)\n                        msg += f'--> Path        : Updated {project.get(\"path\")} to {path}\\n'\n                    if project.get('remote') != remote:\n                        modified_project = True\n                        project.set('remote', remote)\n                        msg += f'--> Remote      : Updated {project.get(\"remote\")} to {remote}\\n'\n                    if project.get('revision') != revision:\n                        modified_project = True\n                        project.set('revision', revision)\n                        msg += f'--> Revision    : Updated {project.get(\"revision\")} to {revision}\\n'\n                    if project.get('clone-depth') != clone_depth:\n                        modified_project = True\n                        project.set('clone-depth', clone_depth)\n                        msg += f'--> Clone depth : Updated {project.get(\"clone-depth\")} to {clone_depth}\\n'\n                    if project.get('name') != name:\n                        modified_project = True\n                        project.set('name', name)\n                        msg += f'--> Repository  : Updated {project.get(\"name\")} to {name}\\n'\n                    if modified_project:\n                        print(f'{name} changed:\\n{msg}\\n')\n\n        # In case the project was not already added, create it.\n        if not found_in_roomservice:\n            print('Adding dependency:')\n            print(f'--> Repository  : {name}')\n            print(f'--> Path        : {path}')\n            print(f'--> Revision    : {revision}')\n            print(f'--> Remote      : {remote}')\n            found_in_roomservice = True\n            modified_project = True\n            attributes = {\n                'path': path,\n                'name': name,\n                'remote': remote,\n                'revision': revision,\n            }\n\n            if clone_depth is not None:\n                attributes['clone-depth'] = clone_depth\n                print(f'--> Clone depth : {clone_depth}')\n\n            print('\\n')\n\n            roomservice_manifest.append(\n                ET.Element('project', attrib=attributes)\n            )\n\n        # In case the project also exists in the main manifest, instruct Repo to ignore that one.\n        for project in upstream_manifest.findall('project'):\n            if project.get('path') == path:\n                upstream_name = project.get('name')\n                found_remove_element = False\n                for removable_project in roomservice_manifest.findall('remove-project'):\n                    if removable_project.get('name') == upstream_name:\n                        found_remove_element = True\n                        break\n                for removable_project in upstream_manifest.findall('remove-project'):\n                    if removable_project.get('name') == upstream_name:\n                        found_remove_element = True\n                        break\n                if not found_remove_element:\n                    modified_project = True\n                    roomservice_manifest.insert(0, ET.Element('remove-project', attrib = {\n                        'name': upstream_name\n                    }))\n\n        # In case anything has changed, set the project as syncable.\n        if modified_project:\n            syncable_projects.append(path)\n\n    # Output our manifest.\n    indent(roomservice_manifest)\n    open(roomservice_manifest_path, 'w').write('\\n'.join([\n        '<?xml version=\"1.0\" encoding=\"UTF-8\"?>',\n        '<!-- You should probably let Roomservice deal with this unless you know what you are doing. -->',\n        ET.tostring(roomservice_manifest).decode()\n    ]))\n\n    #  If roomservice manifest is perfectly fine, check if there are missing repos to be resynced.\n    if len(syncable_projects) == 0:\n        for path in mentioned_projects:\n            if not os.path.exists(path):\n                print('Dependency to be resynced:')\n                print(f'--> Repository Path : {path}\\n')\n                syncable_projects.append(path)\n\n    # Sync the project that have changed and should be synced.\n    if len(syncable_projects) > 0:\n        print('Syncing the dependencies.')\n        if os.system('repo sync --force-sync --quiet --no-clone-bundle --no-tags %s' % ' '.join(syncable_projects)) != 0:\n            raise ValueError('Got an unexpected exit status from the sync process.')\n"
        },
        "PowerFeature.cpp": {
            "code": "/*\n * Copyright (C) 2021, Paranoid Android\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n#define LOG_TAG \"vendor.aospa.power-service\"\n// #define LOG_NDEBUG 0\n\n#include \"PowerFeature.h\"\n\n#include <fcntl.h>\n#include <log/log.h>\n#include <unistd.h>\n\nnamespace aidl {\nnamespace vendor {\nnamespace aospa {\nnamespace power {\n\nstatic constexpr int kInputEventWakeupModeOff = 4;\nstatic constexpr int kInputEventWakeupModeOn = 5;\n\n#ifdef FEATURE_EXT\nextern bool setDeviceSpecificFeature(Feature feature, bool enabled);\n#endif\n\nndk::ScopedAStatus PowerFeature::setFeature(Feature feature, bool enabled) {\n#ifdef FEATURE_EXT\n    if (setDeviceSpecificFeature(feature, enabled)) {\n        return ndk::ScopedAStatus::ok();\n    }\n#endif\n    switch (feature) {\n#ifdef GESTURES_NODE\n        case Feature::GESTURES:\n            sysFsWrite(GESTURES_NODE, enabled);\n            break;\n#endif\n#ifdef TAP_TO_WAKE_NODE\n        case Feature::DOUBLE_TAP:\n            sysFsWrite(TAP_TO_WAKE_NODE, enabled);\n            break;\n#elif defined(TAP_TO_WAKE_EVENT_NODE)\n        case Feature::DOUBLE_TAP:\n            input_event ev;\n            ev.type = EV_SYN;\n            ev.code = SYN_CONFIG;\n            ev.value = enabled ? kInputEventWakeupModeOn : kInputEventWakeupModeOff;\n            sysFsWrite(TAP_TO_WAKE_EVENT_NODE, &ev);\n            break;\n#endif\n#ifdef DRAW_V_NODE\n        case Feature::DRAW_V:\n            sysFsWrite(DRAW_V_NODE, enabled);\n            break;\n#endif\n#ifdef DRAW_INVERSE_V_NODE\n        case Feature::DRAW_INVERSE_V:\n            sysFsWrite(DRAW_INVERSE_V_NODE, enabled);\n            break;\n#endif\n#ifdef DRAW_O_NODE\n        case Feature::DRAW_O:\n            sysFsWrite(DRAW_O_NODE, enabled);\n            break;\n#endif\n#ifdef DRAW_M_NODE\n        case Feature::DRAW_M:\n            sysFsWrite(DRAW_M_NODE, enabled);\n            break;\n#endif\n#ifdef DRAW_W_NODE\n        case Feature::DRAW_W:\n            sysFsWrite(DRAW_W_NODE, enabled);\n            break;\n#endif\n#ifdef DRAW_ARROW_LEFT_NODE\n        case Feature::DRAW_ARROW_LEFT:\n            sysFsWrite(DRAW_ARROW_LEFT_NODE, enabled);\n            break;\n#endif\n#ifdef DRAW_ARROW_RIGHT_NODE\n        case Feature::DRAW_ARROW_RIGHT:\n            sysFsWrite(DRAW_ARROW_RIGHT_NODE, enabled);\n            break;\n#endif\n#ifdef ONE_FINGER_SWIPE_UP_NODE\n        case Feature::ONE_FINGER_SWIPE_UP:\n            sysFsWrite(ONE_FINGER_SWIPE_UP_NODE, enabled);\n            break;\n#endif\n#ifdef ONE_FINGER_SWIPE_RIGHT_NODE\n        case Feature::ONE_FINGER_SWIPE_RIGHT:\n            sysFsWrite(ONE_FINGER_SWIPE_RIGHT_NODE, enabled);\n            break;\n#endif\n#ifdef ONE_FINGER_SWIPE_DOWN_NODE\n        case Feature::ONE_FINGER_SWIPE_DOWN:\n            sysFsWrite(ONE_FINGER_SWIPE_DOWN_NODE, enabled);\n            break;\n#endif\n#ifdef ONE_FINGER_SWIPE_LEFT_NODE\n        case Feature::ONE_FINGER_SWIPE_LEFT:\n            sysFsWrite(ONE_FINGER_SWIPE_LEFT_NODE, enabled);\n            break;\n#endif\n#ifdef TWO_FINGER_SWIPE_NODE\n        case Feature::TWO_FINGER_SWIPE:\n            sysFsWrite(TWO_FINGER_SWIPE_NODE, enabled);\n            break;\n#endif\n#ifdef DRAW_S_NODE\n        case Feature::DRAW_S:\n            sysFsWrite(DRAW_S_NODE, enabled);\n            break;\n#endif\n#ifdef SINGLE_TAP_TO_WAKE_NODE\n        case Feature::SINGLE_TAP:\n            sysFsWrite(SINGLE_TAP_TO_WAKE_NODE, enabled);\n            break;\n#endif\n        default:\n            return ndk::ScopedAStatus::fromServiceSpecificError(ENOTSUP);\n    }\n\n    return ndk::ScopedAStatus::ok();\n}\n\nvoid PowerFeature::sysFsWrite(const char *file_node, bool enabled) {\n    int fd, rc;\n    fd = open(file_node, O_WRONLY);\n    if (fd < 0) {\n        ALOGE(\"Failed to open %s, %d\", file_node, fd);\n        return;\n    }\n\n    rc = write(fd, enabled ? \"1\" : \"0\", 1);\n    if (rc < 0) {\n        ALOGE(\"Failed to write \\\"%d\\\" to %s\", enabled, file_node);\n    }\n\n    close(fd);\n}\n\nvoid PowerFeature::sysFsWrite(const char *file_node, const input_event *ev) {\n    int fd, rc;\n    fd = open(file_node, O_WRONLY);\n    if (fd < 0) {\n        ALOGE(\"Failed to open %s, %d\", file_node, fd);\n        return;\n    }\n\n    rc = write(fd, ev, sizeof(*ev));\n    if (rc < 0) {\n        ALOGE(\"Failed to write \\\"%d\\\" to %s\", ev->value, file_node);\n    }\n\n    close(fd);\n}\n\n}  // namespace power\n}  // namespace aospa\n}  // namespace vendor\n}  // namespace aidl\n"
        },
        "main.cpp": {
            "code": "/*\n * Copyright (C) 2021, Paranoid Android\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n#define LOG_TAG \"vendor.aospa.power-service\"\n\n#include <android-base/logging.h>\n#include <android/binder_manager.h>\n#include <android/binder_process.h>\n\n#include \"PowerFeature.h\"\n\nusing ::aidl::vendor::aospa::power::PowerFeature;\n\nint main() {\n    ABinderProcess_setThreadPoolMaxThreadCount(0);\n    std::shared_ptr<PowerFeature> powerFeature = ndk::SharedRefBase::make<PowerFeature>();\n    if (!powerFeature) {\n        return EXIT_FAILURE;\n    }\n\n    const std::string instance = std::string(PowerFeature::descriptor) + \"/default\";\n    binder_status_t status =\n            AServiceManager_addService(powerFeature->asBinder().get(), instance.c_str());\n    CHECK(status == STATUS_OK);\n\n    ABinderProcess_joinThreadPool();\n    return EXIT_FAILURE; // should not reached\n}\n"
        },
        "current.txt": {
            "code": "415479283d17219b992d6de758ab4b56ecbbac8e6c5d157acf98d6e7270056c5  vendor.qti.hardware.btconfigstore@1.0::types\n04a894025ae70cb5821de82289b1a13426583696a4d3bf99042d0a25b615c10a  vendor.qti.hardware.btconfigstore@1.0::IBTConfigStore\n\n3c637d840916d6affda8b35359df37ea0510964242109b9e558ae8276a205d29  vendor.qti.hardware.btconfigstore@2.0::types\n3fd14e41ed74c712f74b34d930e595666a838945c1877b49825160106a3d932d  vendor.qti.hardware.btconfigstore@2.0::IBTConfigStore\n"
        },
        "Usb.cpp": {
            "code": "/*\n * Copyright (C) 2020 The LineageOS Project\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n#include <pthread.h>\n#include <stdio.h>\n#include <sys/types.h>\n#include <unistd.h>\n\n#include <android-base/logging.h>\n#include <utils/Errors.h>\n#include <utils/StrongPointer.h>\n\n#include \"Usb.h\"\n\nnamespace android {\nnamespace hardware {\nnamespace usb {\nnamespace V1_0 {\nnamespace implementation {\n\nReturn<void> Usb::switchRole(const hidl_string &portName __unused,\n                             const PortRole &newRole __unused) {\n    LOG(ERROR) << __func__ << \": Not supported\";\n    return Void();\n}\n\nReturn<void> Usb::queryPortStatus() {\n    hidl_vec<PortStatus> currentPortStatus;\n    currentPortStatus.resize(1);\n\n    currentPortStatus[0].portName = \"otg_default\";\n    currentPortStatus[0].currentDataRole = PortDataRole::DEVICE;\n    currentPortStatus[0].currentPowerRole = PortPowerRole::SINK;\n    currentPortStatus[0].currentMode = PortMode::UFP;\n    currentPortStatus[0].canChangeMode = false;\n    currentPortStatus[0].canChangeDataRole = false;\n    currentPortStatus[0].canChangePowerRole = false;\n    currentPortStatus[0].supportedModes = PortMode::UFP;\n\n    pthread_mutex_lock(&mLock);\n    if (mCallback != NULL) {\n        Return<void> ret =\n                mCallback->notifyPortStatusChange(currentPortStatus, Status::SUCCESS);\n        if (!ret.isOk()) {\n            LOG(ERROR) << \"queryPortStatus error \" << ret.description();\n        }\n    } else {\n        LOG(INFO) << \"Notifying userspace skipped. Callback is NULL\";\n    }\n    pthread_mutex_unlock(&mLock);\n\n    return Void();\n}\n\nReturn<void> Usb::setCallback(const sp<IUsbCallback> &callback) {\n    pthread_mutex_lock(&mLock);\n\n    mCallback = callback;\n    LOG(INFO) << \"registering callback\";\n\n    pthread_mutex_unlock(&mLock);\n    return Void();\n}\n\n}  // namespace implementation\n}  // namespace V1_0\n}  // namespace usb\n}  // namespace hardware\n}  // namespace android\n"
        }
    }
}